---
layout:     post
title:      "人脸检测、性别、表情分析"
subtitle:   "深度学习"
date:       2017-07-06
author:     "hadxu"
header-img: "img/hadxu.jpg"
tags:
    - 深度学习
    - 人脸
---

# 人脸检测、性别、表情分析

----------
有一段时间没有写博客了， 最近一直在找工作，虽然说已经上研究生了，但是暑假两个月不能浪费，于是到南京来打工了。不得不说，南京工作机遇真多，但是，南京人也多，每次回宿舍都是挤进去的，哎。。。还是无锡好啊。不多说了，今天来我们的重头戏，就是人脸的检测、性别分析、以及表情判断。

----------
### 那么，今天的内容就是
- 通过摄像头将人脸标注出来，这里采用haar算法。
- 将人脸根据模型判断男性还是女性
- 将人脸表情判断出来

#### 环境为

- Python3.5
- opencv
- tensorflow + keras

> 本人开发环境为Windows7，既然能够在Windows上进行编程，在Linux以及Mac OS上更没有什么问题了。


## 第一步，通过摄像头捕捉画面

> 通过电脑摄像头捕捉摄像头的代码如下，Google了一下，目前最简单的是使用opencv工具。

    video_capture = cv2.VideoCapture(0)
	while True:
    # 读取摄像头的视频流
    	_, frame = video_capture.read()
		cv2.imshow('face', frame)
	if cv2.waitKey(30) & ord('q') == 0xFF:
        break

这样，就实现了简单的摄像头捕捉摄像头的画面。

## 第二步，通过haar实现人脸提取。

> 为什么采用haar算法来进行人脸截取。一部分原因在于该算法计算速度特别快，可以在常数时间内进行将人脸标注出来，至于里面的算法的核心思想，我们就不深究了，感兴趣的同学可以参考opencv里面关于haar的介绍。我这里采用haar进行应用。

由于haar分类器算法是xml文本表示的，首先读取相关的xml文件：

	# 读取人脸haar模型
	face_detection = cv2.CascadeClassifier('model/face_detection/haarcascade_frontalface_default.xml')
	
	# 将视频流转换成灰度
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

	# 检测人脸，产生坐标值
    faces = face_detection.detectMultiScale(gray, 1.3, 5)

	for (x, y, w, h) in faces:
		cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 0, 0), 2)

这样，到此为止，就实现了人脸的标注。

## 第三步，通过CNN模型进行性别判断。

CNN模型下一节进行讲解，在这一章中，我们使用训练好的模型进行性别判断：

	# 读取性别判断模型
	gender_classifier = load_model('model/gender/simple_CNN.81-0.96.hdf5')

	gender_labels = {0: 'womam', 1: 'man'}

	# 将视频流中的人像截取出来
	for (x, y, w, h) in faces:
        # 将性别判断出来
        face = frame[(y - 60):(y + h + 60), (x - 30):(x + w + 30)]

        face = cv2.resize(face, (48, 48))
        face = np.expand_dims(face, 0)
        face = face / 255.0
        gender_label_arg = np.argmax(gender_classifier.predict(face))
		# 将性别判断出来并映射到对应的标签
        gender = gender_labels[gender_label_arg]

## 第四步，将人脸表情判断出来

同样的，我们采用训练好的模型：

	# 读取情绪判别模型
	emotion_classifier = load_model('model/emotion/simple_CNN.530-0.65.hdf5')
	emotion_labels = {0: 'angry', 1: 'disgust', 2: 'fear', 3: 'happy',
                  4: 'sad', 5: 'surprise', 6: 'neutral'}

	gray_face = gray[(y - 40):(y + h + 40), (x - 20):(x + w + 20)]
    gray_face = cv2.resize(gray_face, (48, 48))
    gray_face = gray_face / 255.0
    gray_face = np.expand_dims(gray_face, 0)
    gray_face = np.expand_dims(gray_face, -1)
    emotion_label_arg = np.argmax(emotion_classifier.predict(gray_face))
    emotion = emotion_labels[emotion_label_arg]

最终，将人脸框、性别、表情都进行打印出来。

    cv2.rectangle(frame, (x, y), (x + w, y + h), gender_color, 2)
    cv2.putText(frame, gender, (x, y - 30), font, .7, gender_color, 1, cv2.LINE_AA)
    cv2.putText(frame, emotion, (x + 90, y - 30), font, .7, gender_color, 1, cv2.LINE_AA)
    cv2.imshow('face', frame)

## 结束，最终的效果如下：

![img](/img/in-post/face.png)

github地址为[face_emotion](https://github.com/HadXu/machine-learning/tree/master/face_detection_and_emotion)

