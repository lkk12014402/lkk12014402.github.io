---
layout:     post
title:      "GAN实战指南"
subtitle:   "GAN"
date:       2018-01-23
author:     "hadxu"
header-img: "img/in-post/cs224n/cs224n_head.png"
tags:
    - Pytorch
    - Python
    - GAN
---

# GAN生成动漫人物指南

自从14年GAN提出，就引起了非常大的反响，以至于Lecun说了一句话“GAN is the most interesting idea in the last 10 years in machine learning"。很遗憾，直到上研究生才深入了解该算法。

## GAN的思想

> GAN是类似于左右互博之术，给定一批真实的数据集，以及随机生成的一批假的数据集投放到生成器(G)，首先有一个网络叫判别器(D),它用来判断样本的真假，对于真实的样本，D需要判断出来，对于假的样本，D同样需要判断出来，因此D在不断的学习，同时，对于生成的假的样本，我们需要将其与真实的标签距离越小越好，因此生成器G也在学习，一个网络在判别，而另一个网络在生成，两个网络同时进行，两个网络互相对抗，在数学理论上是可以达到平衡的地步，因此这就称为生成对抗网络。

### GAN实现动漫人物的生成
这里采用的数据集为知乎用户何之源提供的动漫人物数据[data](https://pan.baidu.com/s/1eSifHcA),密码g5qa。由于我们使用的为Pytorch自带的ImageFloder方法，所以将数据集保存为如下形式
```
-data
    -face
        - ...jpg
        - ...jpg
        ....
```


### 生成网络的搭建 

首先是网络的搭建，这里采用的网络为DCGAN论文中的图[Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434),
网络图如下:

![](/img/in-post/DCGAN.jpg)

> 解释:首先是100维噪声，维度为```100*1*1```,然后经过一层**上卷积**(下卷积的逆操作)，下卷积如果没有padding的话，随着网络的加深，数据的长宽会越来越小，而channel会越来越深，反之，上卷积则是长宽越来越大，而channel越来越小。如图所示，输入的为```100*1*1```,经过一层上卷积以后，变为```1024*4*4```,在此上卷积```512*8*8```,直到最后一层```3*64*64```。

**这里有一个非常重要的公式，假设一幅图片的宽为```w```,卷积核大小为```k```,步长为```s```,padding大小为```p```,那么经过下卷积以后的图像大小为```(w-k+2p)/s+1```,反之，上采样将公式逆转即可。**

### 下面来介绍判别器网络

> 判别器网络就是普通的神经网络，将3维的图像放入网络中，最后输出的为```Sigmoid```，用来判断一个图片的真假程度。

### 编码

首先是网络的结构
```
import torch.nn as nn


class NetG(nn.Module):
    def __init__(self, opt):
        super(NetG, self).__init__()
        ngf = opt.ngf
        self.main = nn.Sequential(
            # in_channels, out_channels, kernel_size, stride=1,padding=0,
            # output_padding=0, groups=1, bias=True, dilation=1
            nn.ConvTranspose2d(opt.nz, ngf * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(ngf * 8),
            nn.ReLU(True),
            # (ngf*8) * 4 * 4

            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 4),
            nn.ReLU(True),
            # (ngf*4)*8*8

            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf * 2),
            nn.ReLU(True),
            # (ngf*2)*16*16

            nn.ConvTranspose2d(ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ngf),
            nn.ReLU(True),
            # (ngf)*32*32


            # (N-f+2p)/stride + 1

            nn.ConvTranspose2d(ngf, 3, 5, 3, 1, bias=False),
            nn.Tanh()
            # 3*96*96
        )

    def forward(self, input):
        return self.main(input)


class NetD(nn.Module):
    def __init__(self, opt):
        super(NetD, self).__init__()
        ndf = opt.ndf
        self.main = nn.Sequential(
            nn.Conv2d(3, ndf, 5, 3, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            # (ndf)*32*32
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 2),
            nn.LeakyReLU(0.2, inplace=True),
            # (ndf*2)*16*16

            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 4),
            nn.LeakyReLU(0.2, inplace=True),
            # (ndf*4) * 8 * 8

            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(ndf * 8),
            nn.LeakyReLU(0.2, inplace=False),
            # (ndf*8) * 4 * 4

            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        return self.main(input).view(-1)
```

在这里，我们采用了传入参数的方法，那么参数的方法为

```
class Config(object):
    data_path = 'data/'
    num_workers = 4
    image_size = 96
    batch_size = 256
    max_epoch = 200
    lr1 = 2e-4
    lr2 = 2e-4
    beta1 = 0.5
    use_gpu = False
    nz = 100
    ngf = 64
    ndf = 64
    save_path = 'imgs/'

    plot_every = 1

    d_every = 1
    g_every = 1
    decay_every = 1

    netd_path = ''
    netg_path = ''

    gen_img = 'result.png'

    gen_num = 64
    gen_search_num = 512
    gen_mean = 0
    gen_std = 1
```

那么整个的训练过程如下:

##### 首选读入数据

```
transform = transforms.Compose([
    transforms.Scale(opt.image_size),
    transforms.CenterCrop(opt.image_size),
    transforms.ToTensor(),
    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
])

dataset = ImageFolder(opt.data_path, transform=transform)

dataloader = DataLoader(dataset, batch_size=opt.batch_size, shuffle=True, num_workers=opt.num_workers, drop_last=True)
```

##### 定义两个网络

```
netd = NetD(opt)
netg = NetG(opt)
```

##### 训练前配置

```
optimizer_g = Adam(netg.parameters(), opt.lr1, betas=(opt.beta1, 0.999))
optimizer_d = Adam(netd.parameters(), opt.lr2, betas=(opt.beta1, 0.999))

criterion = nn.BCELoss()

true_labels = Variable(torch.ones(opt.batch_size))
fake_labels = Variable(torch.zeros(opt.batch_size))
fix_noises = Variable(torch.randn(opt.batch_size, opt.nz, 1, 1))
noises = Variable(torch.randn(opt.batch_size, opt.nz, 1, 1))
```

##### 首先训练判别器

```
optimizer_d.zero_grad()
output = netd(real_img)
error_d_real = criterion(output, true_labels)
error_d_real.backward()
noises.data.copy_(torch.randn(opt.batch_size, opt.nz, 1, 1))

fake_img = netg(noises).detach()
fake_output = netd(fake_img)
error_d_fake = criterion(fake_output, fake_labels)
error_d_fake.backward()
```

##### 训练生成器

```
optimizer_g.zero_grad()
noises.data.copy_(torch.randn(opt.batch_size, opt.nz, 1, 1))
fake_img = netg(noises)
fake_output = netd(fake_img)
error_g = criterion(fake_output, true_labels)
error_g.backward()
optimizer_g.step()
```

##### 将结果可视化

>  在这里强烈推荐一个tensorboardX库，可以将可视化结果描述起来,官方地址为[tensorboard-pytorch](http://tensorboard-pytorch.rtfd.io)

```
fix_fake_imgs = netg(fix_noises)

fake = fix_fake_imgs[:64] * 0.5 + 0.5
real = real_img[:64] * 0.5 + 0.5

writer.add_image('image/fake_Image', fake, ii)
writer.add_image('image/real_Image', real, ii)
```

##### 效果

经过几个小时的训练，可以看到一些效果

经过10轮

![](/img/in-post/GAN1.jpg)

经过50轮

![](/img/in-post/GAN2.jpg)

经过100轮

![](/img/in-post/GAN3.jpg)

可以发现，效果越来越好。GAN可以干的事情很多，这里有一个网站[gan-zoo](https://github.com/hindupuravinash/the-gan-zoo)
,非常有意思，另外还有一个CycleGAN，也特别有意思。

代码在[GAN-github](https://github.com/HadXu/machine-learning/tree/master/pytorch_tutorial/%E6%A8%A1%E5%9E%8B%E5%AE%9E%E7%8E%B0/GAN_tutorial)